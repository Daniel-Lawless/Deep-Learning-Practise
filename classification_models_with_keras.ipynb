{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:41.776418Z",
     "start_time": "2025-09-17T14:53:41.773247Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical  # Used for converting the target values into a one-hot-encoding format.\n",
    "from keras.datasets import mnist # This data is already divided into a train and test set\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:41.966934Z",
     "start_time": "2025-09-17T14:53:41.781882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape\n",
    "# We have 60000 images, each of size 28 x 28. The reason it does not have dimension (60000, 28, 28, 3) is because the images\n",
    "# are grayscale, meaning that instead of having a red, green, blue value per pixel, each pixel has one value between 0 and 255 that represents\n",
    "# the pixels intensity, 0 being black, and 255 being white."
   ],
   "id": "fee356e5c575a7e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:42.072931Z",
     "start_time": "2025-09-17T14:53:41.978718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's look at an example of an image\n",
    "plt.imshow(X_train[0])"
   ],
   "id": "ad385363eeb21437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28c4a4ded50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:42.146820Z",
     "start_time": "2025-09-17T14:53:42.082417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For conventional NNs, we cannot input the image as is, so we have to each image into 1 dimensional vectors\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1).astype('float32')\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1).astype('float32')\n",
    "\n",
    "X_train_flatten.shape\n",
    "# Each of these values represent the pixel intensity in this one image.\n",
    "# Each row represents an image."
   ],
   "id": "9d34a9a693d60516",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:42.185226Z",
     "start_time": "2025-09-17T14:53:42.157351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# normalize data. (Since pixel intensity is between 0 and 255, dividing by 255 will rescale the pixel values to between 0 and 1)\n",
    "X_train_flatten /= 255\n",
    "X_test_flatten /= 255\n",
    "\n",
    "# We also need to divide our y_train and y_test into categories.\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "y_train_cat.shape # We can see now each target has 10 values, it will have a value of 1 in the class that datapoint takes, and 0 else where."
   ],
   "id": "7ed31652be5ee009",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:53:42.198824Z",
     "start_time": "2025-09-17T14:53:42.195001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_cols = X_train_flatten.shape[1]\n",
    "\n",
    "# Define model architecture\n",
    "def conventional_NN_model():\n",
    "    # Define model and input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_cols,)))\n",
    "\n",
    "    # Define hidden layers\n",
    "    model.add(Dense((24*24), activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "\n",
    "    # Define output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Define optimization, loss, and evaluation metric\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "381e14befae97f2a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:54:39.424867Z",
     "start_time": "2025-09-17T14:53:42.205503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build model\n",
    "conventional_NN_model = conventional_NN_model()\n",
    "\n",
    "# Train model\n",
    "conventional_NN_model.fit(X_train_flatten, y_train_cat, epochs=10, validation_split=0.1, verbose=2)"
   ],
   "id": "39245263f9923cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 - 6s - 4ms/step - accuracy: 0.9403 - loss: 0.1983 - val_accuracy: 0.9695 - val_loss: 0.1082\n",
      "Epoch 2/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9742 - loss: 0.0831 - val_accuracy: 0.9758 - val_loss: 0.0803\n",
      "Epoch 3/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9822 - loss: 0.0555 - val_accuracy: 0.9788 - val_loss: 0.0732\n",
      "Epoch 4/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9871 - loss: 0.0401 - val_accuracy: 0.9785 - val_loss: 0.0748\n",
      "Epoch 5/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9901 - loss: 0.0311 - val_accuracy: 0.9793 - val_loss: 0.0752\n",
      "Epoch 6/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9911 - loss: 0.0272 - val_accuracy: 0.9803 - val_loss: 0.0870\n",
      "Epoch 7/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.9792 - val_loss: 0.0825\n",
      "Epoch 8/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9942 - loss: 0.0178 - val_accuracy: 0.9797 - val_loss: 0.0937\n",
      "Epoch 9/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9938 - loss: 0.0189 - val_accuracy: 0.9828 - val_loss: 0.0788\n",
      "Epoch 10/10\n",
      "1688/1688 - 6s - 3ms/step - accuracy: 0.9951 - loss: 0.0143 - val_accuracy: 0.9807 - val_loss: 0.0921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c5c7f4d60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:54:39.993272Z",
     "start_time": "2025-09-17T14:54:39.496118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scores return the loss first, then whatever you specified in the metrics parameter in the model.compile() function\n",
    "# in the order you specified it. We only included accuracy, so our scores output will be an array of the loss and accuracy.\n",
    "scores = conventional_NN_model.evaluate(X_test_flatten, y_test_cat, verbose=0)\n",
    "print(f\"loss: {scores[0]}, accuracy: {100 * scores[1]:.2f}%\")"
   ],
   "id": "1a407b6c88a5192e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10595040023326874, accuracy: 97.89%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:54:40.118674Z",
     "start_time": "2025-09-17T14:54:39.998267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's see how a CNN will perform.\n",
    "\n",
    "# Reshape images to be a shape a CNN expects.\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\") # Convert to float for normalizing later and 32 bits for deeplearning framework efficiency.\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "\n",
    "# Normalize data\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}, Shape of X_test: {X_test.shape}\")"
   ],
   "id": "6db6e0d7d78aac5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 28, 28, 1), Shape of X_test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:54:40.128746Z",
     "start_time": "2025-09-17T14:54:40.123516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract input shape\n",
    "input_shape = X_train[0].shape\n",
    "\n",
    "# Extract number of classes.\n",
    "num_classes = y_train_cat.shape[1]\n",
    "\n",
    "# Define CNN architecture\n",
    "def CNN(input_shape):\n",
    "    # Define model and input layer.\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # Define the convolutional and pooling layers.\n",
    "    model.add(Conv2D(16, kernel_size=(5,5), strides=(1,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Flatten the dimensions from the pooling layer into dimensions\n",
    "    # the conventional dense layer can understand e.g., (min_batch_size, num_features)\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Define the conventional portion of the CNN\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # define the loss function to optimize, the optimizer to achieve the optimization, and the evaluation metric.\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "id": "3c855dddb5d3001a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:55:37.178710Z",
     "start_time": "2025-09-17T14:54:40.137940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build model\n",
    "CNN_model = CNN(input_shape)\n",
    "\n",
    "# Train model\n",
    "CNN_model.fit(X_train_norm, y_train_cat, batch_size=32, epochs=10, verbose=2)"
   ],
   "id": "c17f42d21801d018",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9520 - loss: 0.1581\n",
      "Epoch 2/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9831 - loss: 0.0542\n",
      "Epoch 3/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9888 - loss: 0.0356\n",
      "Epoch 4/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9918 - loss: 0.0252\n",
      "Epoch 5/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9944 - loss: 0.0181\n",
      "Epoch 6/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9949 - loss: 0.0147\n",
      "Epoch 7/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9964 - loss: 0.0103\n",
      "Epoch 8/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9970 - loss: 0.0087\n",
      "Epoch 9/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9975 - loss: 0.0073\n",
      "Epoch 10/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9981 - loss: 0.0057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c5c7f5480>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:55:37.862624Z",
     "start_time": "2025-09-17T14:55:37.195707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the CNN model with one convolutional and pooling layer\n",
    "scores = CNN_model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"Loss: {scores[0]}, Accuracy: {100 * scores[1]:.2f}%\")"
   ],
   "id": "d9fd08b72f880e86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.046168435364961624, Accuracy: 98.91%\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:55:37.877003Z",
     "start_time": "2025-09-17T14:55:37.872546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's instead define a CNN with 2 convolutional and pooling and layers.\n",
    "def convolutional_network(input_shape):\n",
    "    # Define model and input layer\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # Define first convolutional and pooling layer.\n",
    "    model.add(Conv2D(16, kernel_size=(5,5), strides=(1,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Define second convolutional and pooling layer\n",
    "    model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Flatten the dimensions from the pooling layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Define the conventional portion of the CNN\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Define the optimizer, loss function, and evaluation metrics\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "id": "ce9e0db350230992",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T15:05:42.013626Z",
     "start_time": "2025-09-17T15:04:43.974370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build and train model\n",
    "convolutional_network_model = convolutional_network(input_shape)\n",
    "convolutional_network_model.fit(X_train_norm, y_train_cat, batch_size=32, epochs=10, verbose=2, validation_split=0.2)"
   ],
   "id": "969f8422b1750c11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9445 - loss: 0.1829 - val_accuracy: 0.9764 - val_loss: 0.0776\n",
      "Epoch 2/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9815 - loss: 0.0587 - val_accuracy: 0.9793 - val_loss: 0.0673\n",
      "Epoch 3/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9876 - loss: 0.0392 - val_accuracy: 0.9860 - val_loss: 0.0448\n",
      "Epoch 4/10\n",
      "1500/1500 - 5s - 4ms/step - accuracy: 0.9899 - loss: 0.0303 - val_accuracy: 0.9879 - val_loss: 0.0364\n",
      "Epoch 5/10\n",
      "1500/1500 - 5s - 4ms/step - accuracy: 0.9925 - loss: 0.0230 - val_accuracy: 0.9879 - val_loss: 0.0386\n",
      "Epoch 6/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9941 - loss: 0.0182 - val_accuracy: 0.9855 - val_loss: 0.0496\n",
      "Epoch 7/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9953 - loss: 0.0149 - val_accuracy: 0.9883 - val_loss: 0.0431\n",
      "Epoch 8/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9962 - loss: 0.0116 - val_accuracy: 0.9893 - val_loss: 0.0485\n",
      "Epoch 9/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9961 - loss: 0.0113 - val_accuracy: 0.9887 - val_loss: 0.0504\n",
      "Epoch 10/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.9877 - val_loss: 0.0531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c5bd26360>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T15:05:42.827632Z",
     "start_time": "2025-09-17T15:05:42.025060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the CNN model with two convolutional and pooling layers\n",
    "scores = convolutional_network_model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"Loss: {scores[0]:.5f}, Accuracy: {100 * scores[1]:.2f}%\")"
   ],
   "id": "7f55af7aed032259",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04497, Accuracy: 99.02%\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:56:31.369766Z",
     "start_time": "2025-09-17T14:56:31.287824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training can take a really long time, and can be computationally expensive, so we can save our models.\n",
    "conventional_NN_model.save(\"conventional_NN_model_MNIST.keras\")\n",
    "CNN_model.save(\"CNN_model_MNIST.keras\")\n",
    "convolutional_network_model.save(\"Convolutional_network_model_MNIST.keras\")"
   ],
   "id": "53b0a6391355900c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:56:31.636704Z",
     "start_time": "2025-09-17T14:56:31.374943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Then, when we are ready to use the model, we can load it.\n",
    "conventional_NN_model = keras.models.load_model(\"conventional_NN_model_MNIST.keras\")\n",
    "CNN_model = keras.models.load_model(\"CNN_model_MNIST.keras\")\n",
    "convolutional_network_model = keras.models.load_model(\"Convolutional_network_model_MNIST.keras\")"
   ],
   "id": "2ac202fca5f83fbf",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T14:56:31.644438Z",
     "start_time": "2025-09-17T14:56:31.641264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In this notebook I learned how to use the Keras library to build a conventional NN and a CNN architecture\n",
    "# for classification problems using the keras library, how to perform basic evaluation of a conventional\n",
    "# NN and a CNNs performance, and how and why we must one-hot-encode target class values. I also learned\n",
    "# how to save and load a model using Keras."
   ],
   "id": "7c09e65460d408f",
   "outputs": [],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
